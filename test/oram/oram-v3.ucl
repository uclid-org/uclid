(*===========================================================
 * Model of Oblivious RAM (Path ORAM) proposed by Stefanov et al.
 * (as described in sample C# code)
 *===========================================================
 *)


(* Models a Path ORAM where the binary tree has depth L=3, so 15 nodes/buckets 
 *
 * Main difference with oram-simple.ucl: Each bucket has Z > 1 elements
 * Number of leaves is 8 (2^L)
 *
 * Marten van Dijk says that the number of blocks should equal the number of leaves.
 * Right now, this model assumes there could be more blocks than leaves.
 *)

(*-------------------------------------------------------------------------*)
MODEL oram

(* global type declarations *)
(* typedef optype : enum{READ, WRITE}; UNUSED RIGHT NOW *)

(*-------------------------------------------------------------------------*)
(* global constants *)
CONST

RANDOM : BITVECFUNC[3]; (* "randomly" generates a LEAF INDEX *)

ARB_BLOCK : BITVECFUNC[16]; (* yields arbitrary block ID *)

test_block_id : BITVEC[16];

CACHE_SZ : BITVEC[8];

(*-------------------------------------------------------------------------*)
MODULE O

INPUT

id_input : BITVEC[16]; (* Block IDs are 16 bit wide *)
(* op_input : optype; *)


VAR

(* STATE VARIABLES *)
position_map_state : BITVECFUNC[3]; (* maps block ID to leaf position *)

(* variable below used in the previous model of an infinitely-large cache *)
(* cache_state : PRED[1]; *) (* maps block ID to a Boolean flag indicating whether or not that block is in the cache *)

(* Model finite size cache as an array of 16 elements *)
cache_present : PRED[1]; (* maps block ID to a Boolean flag indicating whether or not that block is in the cache *)
cache_location : BITVECFUNC[8]; (* maps block ID to the location of the block in the cache *)
cache_contents : BITVECFUNC[16]; (* maps a 4-bit location to ID of the block stored there, if any *)
cache_num_elements : BITVEC[8]; (* keeps track of the number of elements in the cache *)
cache_pos : BITVEC[8]; (* location at which to insert the next element into the cache *)

buckets_state : BITVECFUNC[16]; (* maps node ID to a single bucket location that can store one block *)

arb_ctr : BITVEC[32]; (* used in arbitrary value generator *)

(*OUTPUTS*)

(* no outputs for now *)


CONST

(* For use as indices of Lambda expressions *)
a : BITVEC[16];
i : BITVEC[16];
j : BITVEC[4];

(* init_cache_state : PRED[1]; *)
init_cache_present : PRED[1];
init_cache_location : BITVECFUNC[4];
init_cache_contents : BITVECFUNC[16];
init_cache_num_elements : BITVEC[8];

init_buckets_state : BITVECFUNC[16];
init_position_map : BITVECFUNC[3];

DEFINE

(* Constants *)

zero_bit := (0x0 # [0:0]);
one_bit := (0x1 # [0:0]);

LEAFCOUNT := (0x08 # [3:0]);

ucl_hex_1_4bit := (0x01 # [3:0]);

CACHE_START := (0x00 # [7:0]);  (* starting location into which cache elements are inserted *)

CACHE_INVALID_LOC := (0xFF # [7:0]); (* "invalid location" in local cache; indicates entry is not in cache *)

(* Some predicates on the state of the finite-sized local cache *)
cacheFull := cache_num_elements = CACHE_SZ;
cacheNumInv := (cache_num_elements >=u 0x00) & (cache_num_elements <=u CACHE_SZ) & (CACHE_SZ > 0x04);
cacheHasSpace := cache_num_elements <=u (CACHE_SZ -_8 0x04);

cacheSzConstraint := (CACHE_SZ <u 0xFF); (* thus 0xFF cannot be a valid location in the local cache *)

(* STEP 1: Remap block *)

oldPosition := position_map_state(id_input);

newPosition := RANDOM(id_input); (* FIXME: ideally, it should be based on a generator of arbitrary values 
                                  * However this is only needed to model the cryptographic randomness in the ORAM scheme
                                  *)

(* STEP 2: Read path *)

oldPosition_4bits := (zero_bit @ oldPosition);

bucketIndex3 := (LEAFCOUNT -_4 ucl_hex_1_4bit) +_4 oldPosition_4bits;
bucket_level3 := buckets_state(bucketIndex3); (* this is the blockId *)

(* enforce this condition to hold -- the block present at 
 * the leaf level is id_input.
 *)
input_block_is_at_leaf := (id_input = bucket_level3);

(* Indices of buckets to read into the local cache *)

bucketIndex2 := ((bucketIndex3 -_4 ucl_hex_1_4bit) >>_4 1); (* logical right shift *)
bucket_level2 := buckets_state(bucketIndex2); (* this is the blockId *)

bucketIndex1:= ((bucketIndex2 -_4 ucl_hex_1_4bit) >>_4 1); (* logical right shift *)
bucket_level1 := buckets_state(bucketIndex1); (* this is the blockId *)

bucketIndex0 := ((bucketIndex1 -_4 ucl_hex_1_4bit) >>_4 1); (* logical right shift *)
bucket_level0 := buckets_state(bucketIndex0); (* this is the blockId *)

(* Make cache updates -- level 3 written first *)

inter_cache_present0 := Lambda(i).
  case
    ~cacheFull & (i = bucket_level3) : true;
    default : cache_present(i);
  esac;

inter_cache_location0 := Lambda(i).
  case
    ~cacheFull & (i = bucket_level3) : cache_num_elements;
    default : cache_location(i);
  esac;

inter_cache_contents0 := Lambda(i).
  case
    ~cacheFull & (i = cache_num_elements) : bucket_level3;
    default : cache_contents(i);
  esac;

cache_num_elements0 :=
  case
    ~cacheFull : cache_num_elements +_8 0x01;
    default : cache_num_elements;
  esac;

cacheFull0 := cache_num_elements0 = CACHE_SZ;

(* ---- *)

inter_cache_present1 := Lambda(i).
  case
    ~cacheFull0 & (i = bucket_level2) : true;
    default : inter_cache_present0(i);
  esac;

inter_cache_location1 := Lambda(i).
  case
    ~cacheFull0 & (i = bucket_level2) : cache_num_elements0;
    default : inter_cache_location0(i);
  esac;

inter_cache_contents1 := Lambda(i).
  case
    ~cacheFull0 & (i = cache_num_elements0) : bucket_level2;
    default : inter_cache_contents0(i);
  esac;

cache_num_elements1 :=
  case
    ~cacheFull0 : cache_num_elements0 +_8 0x01;
    default : cache_num_elements0;
  esac;

cacheFull1 := cache_num_elements1 = CACHE_SZ;

(* ---- *)

inter_cache_present2 := Lambda(i).
  case
    ~cacheFull1 & (i = bucket_level1) : true;
    default : inter_cache_present1(i);
  esac;

inter_cache_location2 := Lambda(i).
  case
    ~cacheFull1 & (i = bucket_level1) : cache_num_elements1;
    default : inter_cache_location1(i);
  esac;

inter_cache_contents2 := Lambda(i).
  case
    ~cacheFull1 & (i = cache_num_elements1) : bucket_level1;
    default : inter_cache_contents1(i);
  esac;

cache_num_elements2 :=
  case
    ~cacheFull1 : cache_num_elements1 +_8 0x01;
    default : cache_num_elements1;
  esac;

cacheFull2 := cache_num_elements2 = CACHE_SZ;

(* ---- *)

inter_cache_present3 := Lambda(i).
  case
    ~cacheFull2 & (i = bucket_level0) : true;
    default : inter_cache_present2(i);
  esac;

inter_cache_location3 := Lambda(i).
  case
    ~cacheFull2 & (i = bucket_level0) : cache_num_elements2;
    default : inter_cache_location2(i);
  esac;

inter_cache_contents3 := Lambda(i).
  case
    ~cacheFull2 & (i = cache_num_elements2) : bucket_level0;
    default : inter_cache_contents2(i);
  esac;

cache_num_elements3 :=
  case
    ~cacheFull2 : cache_num_elements2 +_8 0x01;
    default : cache_num_elements2;
  esac;

cacheFull3 := cache_num_elements3 = CACHE_SZ;

(* ---- *)



(* STEP 3: Search cache for block to set new position 
 * ---> 
 * This is NOT modeled in UCLID because a block simply
 * has its ID and nothing else, not the position.
 * The position is set directly in the position map.
 *)

nxt_position_map_state := Lambda(a).
  case
	(a = id_input) : newPosition;
	default : position_map_state(a);
  esac;

(* STEP 4: Sort cache 
 * --->
 * This step is also NOT modeled due to our simplistic model of the cache 
 * as a Boolean array. Moreover, the sorting operation is rendered moot
 * as we arbitrarily select cache blocks to evict as long as they match the path
 * to be written back to.
 *)


(* STEP 5: Write path *)

(*
 Eject arbitrarily chosen blocks from cache and fill path to
 oldPosition with them -- i.e. use those to update buckets_state
 at locations bucketIndex0--bucketIndex3.
*)
wr_bucket_level0 := ARB_BLOCK(arb_ctr);
wr_bucket_level1 := ARB_BLOCK(wr_bucket_level0);
wr_bucket_level2 := ARB_BLOCK(wr_bucket_level1);
wr_bucket_level3 := ARB_BLOCK(wr_bucket_level2);

(* enforce this condition to hold -- i.e., we are evicting 
 * blocks that are present in the local cache AND they
 * map to the path prefix to the leaf oldPosition
 *)
blocks_present_in_cache := 
    inter_cache_present3(wr_bucket_level0)  
  & inter_cache_present3(wr_bucket_level1) & ((nxt_position_map_state(wr_bucket_level1) >>_3 2) = (oldPosition >>_3 2)) 
  & inter_cache_present3(wr_bucket_level2) & ((nxt_position_map_state(wr_bucket_level2) >>_3 1) = (oldPosition >>_3 1))  
  & inter_cache_present3(wr_bucket_level3) & (nxt_position_map_state(wr_bucket_level3) = oldPosition);


inter_cache_num_elements4 := cache_num_elements3 -_8 0x01;

inter_cache_location4 := Lambda(i).
  case
    i = wr_bucket_level3 : CACHE_INVALID_LOC; (* evicted *)
    i = inter_cache_contents3(inter_cache_num_elements4) : inter_cache_location3(wr_bucket_level3);
    default : inter_cache_location3(i);
  esac;

inter_cache_contents4 := Lambda(i).
  case
    i = inter_cache_location3(wr_bucket_level3) : inter_cache_contents3(inter_cache_num_elements4);
    default : inter_cache_contents3(i);
  esac;


inter_cache_num_elements5 := inter_cache_num_elements4 -_8 0x01;

inter_cache_location5 := Lambda(i).
  case
    i = wr_bucket_level2 : CACHE_INVALID_LOC; (* evicted *)
    i = inter_cache_contents3(inter_cache_num_elements5) : inter_cache_location4(wr_bucket_level2);
    default : inter_cache_location4(i);
  esac;

inter_cache_contents5 := Lambda(i).
  case
    i = inter_cache_location4(wr_bucket_level2) : inter_cache_contents3(inter_cache_num_elements5);
    default : inter_cache_contents4(i);
  esac;


inter_cache_num_elements6 := inter_cache_num_elements5 -_8 0x01;

inter_cache_location6 := Lambda(i).
  case
    i = wr_bucket_level1 : CACHE_INVALID_LOC; (* evicted *)
    i = inter_cache_contents3(inter_cache_num_elements6) : inter_cache_location5(wr_bucket_level1);
    default : inter_cache_location5(i);
  esac;

inter_cache_contents6 := Lambda(i).
  case
    i = inter_cache_location5(wr_bucket_level1) : inter_cache_contents3(inter_cache_num_elements6);
    default : inter_cache_contents5(i);
  esac;


inter_cache_num_elements7 := inter_cache_num_elements6 -_8 0x01;

inter_cache_location7 := Lambda(i).
  case
    i = wr_bucket_level0 : CACHE_INVALID_LOC; (* evicted *)
    i = inter_cache_contents3(inter_cache_num_elements7) : inter_cache_location6(wr_bucket_level0);
    default : inter_cache_location6(i);
  esac;

inter_cache_contents7 := Lambda(i).
  case
    i = inter_cache_location6(wr_bucket_level0) : inter_cache_contents3(inter_cache_num_elements7);
    default : inter_cache_contents6(i);
  esac;

nxt_cache_location := Lambda(i). inter_cache_location7(i);

nxt_cache_contents := Lambda(i). inter_cache_contents7(i);

ASSIGN

(* used in the generation of arbitrary values *)
init[arb_ctr] := 0x00000000;
next[arb_ctr] := arb_ctr +_32 0x00000001;

(* --------- Updates to variables used for modeling finite local cache ---------- *)

init[cache_present] := Lambda(i). init_cache_present(i);
next[cache_present] := Lambda(i).
  case
    (* writes made last in the "Write path" phase come first in this update *)
    i = wr_bucket_level0 & inter_cache_present3(i) : false;
    i = wr_bucket_level1 & inter_cache_present3(i) : false;
    i = wr_bucket_level2 & inter_cache_present3(i) : false;
    i = wr_bucket_level3 & inter_cache_present3(i) : false;
    (* then the reads in the "Read path" phase *)
    default : inter_cache_present3(i);    
  esac;

init[cache_location] := Lambda(i). 
  case
    i >= init_cache_num_elements : CACHE_INVALID_LOC;
    default : init_cache_location(i);
  esac;
next[cache_location] := Lambda(i). nxt_cache_location(i); 


init[cache_contents] := Lambda(i). init_cache_contents(i);
next[cache_contents] := Lambda(i). nxt_cache_contents(i);

init[cache_num_elements] := init_cache_num_elements;
next[cache_num_elements] := inter_cache_num_elements7;


(* --------- Local cache updates end ---------- *)


(* Updates to the position map *)
init[position_map_state] := Lambda(a). init_position_map(a);
next[position_map_state] := Lambda(a). nxt_position_map_state(a);

(* Updates to buckets in the ORAM tree *)
init[buckets_state] := Lambda(j). init_buckets_state(j);
next[buckets_state] := Lambda(j).
  case
    j = bucketIndex0 : wr_bucket_level0;
    j = bucketIndex1 : wr_bucket_level1;
    j = bucketIndex2 : wr_bucket_level2;
    j = bucketIndex3 : wr_bucket_level3;
    default : buckets_state(j);
  esac;


(*====================================================*)
CONTROL

EXTVAR

id_input : BITVEC[16] := test_block_id;

STOREVAR

init_inv : PRED[1];
next_inv : PRED[1];
assertion : TRUTH;

store_map_b : BITVEC[3];
store_bucketId : BITVEC[4];

store_bucketlevel3 : BITVEC[16];

store_oldPos4bits : BITVEC[4];

store_precond : TRUTH;

VAR


CONST

a : BITVEC[16]; 
b : BITVEC[16]; 

i : BITVEC[3];

DEFINE

zero_bit := (0x0 # [0:0]);
one_bit := (0x1 # [0:0]);

LEAFCOUNT := (0x08 # [3:0]);

ucl_hex_1_4bit := (0x01 # [3:0]);

pre_cond := O.input_block_is_at_leaf & O.blocks_present_in_cache & O.cacheSzConstraint;

a_pos := O.position_map_state(a);
a_pos_4bits := (zero_bit @ a_pos);

bucketIndex3 := (LEAFCOUNT -_4 ucl_hex_1_4bit) +_4 a_pos_4bits;
bucket_level3 := O.buckets_state(bucketIndex3); (* this is the blockId *)

bucketIndex2 := ((bucketIndex3 -_4 ucl_hex_1_4bit) >>_4 1); (* logical right shift *)
bucket_level2 := O.buckets_state(bucketIndex2); (* this is the blockId *)

bucketIndex1:= ((bucketIndex2 -_4 ucl_hex_1_4bit) >>_4 1); (* logical right shift *)
bucket_level1 := O.buckets_state(bucketIndex1); (* this is the blockId *)

bucketIndex0 := ((bucketIndex1 -_4 ucl_hex_1_4bit) >>_4 1); (* logical right shift *)
bucket_level0 := O.buckets_state(bucketIndex0); (* this is the blockId *)

(* "a" is either in the local cache or it is present along the path to the leaf it is mapped to *)
(* an auxiliary invariant on the number of cache entries is added -- this should hold *)
(* In this version, we additionally check that at the end of the access, the cache still has
 * space for 4 elements.
 *)
inv := Lambda(a). (O.cache_present(a) | (a = bucket_level0) 
                | (a = bucket_level1) | (a = bucket_level2) | (a = bucket_level3)) & O.cacheHasSpace & O.cacheNumInv;


EXEC

initialize;

init_inv := Lambda(b). inv(b);

store_map_b := O.oldPosition;

store_bucketId := O.bucketIndex3;

store_bucketlevel3 := O.bucket_level3;

store_oldPos4bits := O.oldPosition_4bits;

store_precond := pre_cond;

simulate(1);

next_inv := Lambda(b). inv(b);


decide(FORALL(a) (init_inv(a)) => FORALL(b) (store_precond => next_inv(b)));


(*
SANITY CHECKS
decide(O.bucketIndex0 = 0x0); (* VALID *)
decide(bucketIndex0 = 0x0); (* VALID *)
decide(O.bucketIndex1 = 0x1 | O.bucketIndex1 = 0x2); (* VALID *)
decide(O.bucketIndex2 >=u 0x3 & O.bucketIndex2 <=u 0x6); (* VALID *)
decide(O.bucketIndex3 >=u 0x7 & O.bucketIndex3 <=u 0xe); (* valid *)
*)


print("oldPosition:");
printexpr(store_map_b); 

print("O.bucketIndex3 is:");
printexpr(store_bucketId);

print("O.bucket_level3 is:");
printexpr(store_bucketlevel3);

print("O.oldPosition_4bits is:");
printexpr(store_oldPos4bits);







